# Environment Variables Configuration Example File
# Copy this file to .env.local and fill in your actual configuration

# ===== LLM API Key Configuration =====
# Configure API keys for the LLM services you want to use
# Different modules will use these configurations as needed

# OpenAI API Configuration
# VITE_OPENAI_API_KEY=sk-your-openai-api-key-here

# Google Gemini API Configuration
# VITE_GEMINI_API_KEY=your-gemini-api-key-here

# DeepSeek API Configuration
# VITE_DEEPSEEK_API_KEY=sk-your-deepseek-api-key-here

# ZhiPu AI API Configuration
# VITE_ZHIPU_API_KEY=your-zhipu-api-key-here

# SiliconFlow API Configuration
# VITE_SILICONFLOW_API_KEY=sk-your-siliconflow-api-key-here

# Custom API Configuration (such as Ollama local service)
# VITE_CUSTOM_API_KEY=your-custom-api-key
# VITE_CUSTOM_API_BASE_URL=http://localhost:11434/v1
# VITE_CUSTOM_API_MODEL=qwen2.5:0.5b

# ===== Multiple Custom Models Configuration (New Feature) =====
# Support configuration of unlimited number of custom models, using suffixes to distinguish different models
# Format: VITE_CUSTOM_API_*_<suffix>
# Suffix rules: Can only contain letters (a-z A-Z), numbers (0-9), underscores (_), hyphens (-)
# Not supported: dots (.), spaces, special symbols, etc.

# Ollama Qwen Model Example
# VITE_CUSTOM_API_KEY_qwen3=ollama-qwen3-key
# VITE_CUSTOM_API_BASE_URL_qwen3=http://localhost:11434/v1
# VITE_CUSTOM_API_MODEL_qwen3=qwen3:8b

# Ollama Qwen2.5 Model Example (Note: version numbers separated by underscores)
# VITE_CUSTOM_API_KEY_qwen2_5=ollama-qwen25-key
# VITE_CUSTOM_API_BASE_URL_qwen2_5=http://localhost:11434/v1
# VITE_CUSTOM_API_MODEL_qwen2_5=qwen2.5:14b

# Local Claude Compatible Service Example
# VITE_CUSTOM_API_KEY_claude_local=claude-local-key
# VITE_CUSTOM_API_BASE_URL_claude_local=http://localhost:8080/v1
# VITE_CUSTOM_API_MODEL_claude_local=claude-3-sonnet

# Other Self-built API Service Example
# VITE_CUSTOM_API_KEY_my_llm=my-llm-api-key
# VITE_CUSTOM_API_BASE_URL_my_llm=https://my-api.example.com/v1
# VITE_CUSTOM_API_MODEL_my_llm=my-custom-model

# Note:
# - The following three items are all required: API_KEY, BASE_URL, MODEL (strictly consistent with core implementation)
# - Generated models will be displayed in UI with formatted names (e.g., qwen3 â†’ Qwen3)

# ===== MCP Server Configuration =====
# The following configurations are only needed when using MCP server

# Preferred model provider (when multiple API keys are configured)
# Optional values: openai, gemini, deepseek, siliconflow, zhipu, custom, custom_<suffix>
# Note: Must correspond to the API keys configured above
# Example: If VITE_CUSTOM_API_KEY_qwen3 is configured, you can use custom_qwen3
# MCP_DEFAULT_MODEL_PROVIDER=openai

# HTTP Server Port (default 3000)
# MCP_HTTP_PORT=3000

# Log Level (default debug)
# Optional values: debug, info, warn, error
# MCP_LOG_LEVEL=debug

# Default Language (default zh)
# Optional values: zh, en
# MCP_DEFAULT_LANGUAGE=en

# ===== Google ADK Configuration =====
# Google Agent Development Kit integration settings
# Required for ADK agent functionality

# Google Cloud Project Configuration
VITE_GOOGLE_ADK_PROJECT_ID=your-google-cloud-project-id
VITE_GOOGLE_ADK_LOCATION=us-central1

# Optional: Google Cloud credentials (for production)
# If not provided, will use Application Default Credentials
VITE_GOOGLE_ADK_CREDENTIALS_TYPE=service_account
VITE_GOOGLE_ADK_PRIVATE_KEY_ID=your-private-key-id
VITE_GOOGLE_ADK_PRIVATE_KEY="-----BEGIN PRIVATE KEY-----\nYOUR_PRIVATE_KEY\n-----END PRIVATE KEY-----\n"
VITE_GOOGLE_ADK_CLIENT_EMAIL=your-service-account@your-project.iam.gserviceaccount.com
VITE_GOOGLE_ADK_CLIENT_ID=your-client-id
VITE_GOOGLE_ADK_AUTH_URI=https://accounts.google.com/o/oauth2/auth
VITE_GOOGLE_ADK_TOKEN_URI=https://oauth2.googleapis.com/token
VITE_GOOGLE_ADK_AUTH_PROVIDER_CERT_URL=https://www.googleapis.com/oauth2/v1/certs
VITE_GOOGLE_ADK_CLIENT_CERT_URL=https://www.googleapis.com/robot/v1/metadata/x509/your-service-account%40your-project.iam.gserviceaccount.com

# ADK Feature Toggle
VITE_ADK_ENABLED=true

# ADK Agent Configuration
VITE_ADK_CONTENT_CREATION_ENABLED=true
VITE_ADK_DATA_ANALYSIS_ENABLED=true
VITE_ADK_CODE_GENERATION_ENABLED=true

# ADK Performance Settings
VITE_ADK_MAX_CONCURRENT_AGENTS=3
VITE_ADK_AGENT_TIMEOUT=300000
VITE_ADK_RETRY_ATTEMPTS=2
VITE_ADK_COST_TRACKING=true

# ===== Advanced Multi-Agent Configuration =====
# Enhanced multi-agent orchestration settings

# Primary Agent Configuration (General Purpose)
VITE_AGENT_PRIMARY_MODEL=gpt-4-turbo
VITE_AGENT_PRIMARY_API_KEY=sk-your-primary-api-key
VITE_AGENT_PRIMARY_BASE_URL=https://api.openai.com/v1
VITE_AGENT_PRIMARY_MAX_TOKENS=4096
VITE_AGENT_PRIMARY_TEMPERATURE=0.7
VITE_AGENT_PRIMARY_ROLE=orchestrator

# Specialized Agent Configuration
VITE_AGENT_CODE_REVIEW_MODEL=gpt-4
VITE_AGENT_CODE_REVIEW_API_KEY=sk-your-code-review-key
VITE_AGENT_CODE_REVIEW_BASE_URL=https://api.openai.com/v1
VITE_AGENT_CODE_REVIEW_MAX_TOKENS=8192
VITE_AGENT_CODE_REVIEW_TEMPERATURE=0.3
VITE_AGENT_CODE_REVIEW_ROLE=code-reviewer
VITE_AGENT_CODE_REVIEW_EXPERTISE=javascript,typescript,python,java,security

# Content Creation Agent
VITE_AGENT_CONTENT_MODEL=gpt-4-turbo
VITE_AGENT_CONTENT_API_KEY=sk-your-content-key
VITE_AGENT_CONTENT_BASE_URL=https://api.openai.com/v1
VITE_AGENT_CONTENT_MAX_TOKENS=6144
VITE_AGENT_CONTENT_TEMPERATURE=0.8
VITE_AGENT_CONTENT_ROLE=content-creator
VITE_AGENT_CONTENT_EXPERTISE=articles,blogs,social-media,marketing-copy

# Research Agent
VITE_AGENT_RESEARCH_MODEL=gpt-4
VITE_AGENT_RESEARCH_API_KEY=sk-your-research-key
VITE_AGENT_RESEARCH_BASE_URL=https://api.openai.com/v1
VITE_AGENT_RESEARCH_MAX_TOKENS=8192
VITE_AGENT_RESEARCH_TEMPERATURE=0.4
VITE_AGENT_RESEARCH_ROLE=research-analyst
VITE_AGENT_RESEARCH_EXPERTISE=market-research,data-analysis,competitive-intelligence

# Agent Orchestration Settings
VITE_AGENT_SELECTION_STRATEGY=capability-based
VITE_AGENT_LOAD_BALANCING=round-robin
VITE_AGENT_FAILOVER_TIMEOUT=30
VITE_AGENT_MAX_RETRIES=3
VITE_AGENT_INTERACTION_MODE=collaborative
VITE_AGENT_SHARED_CONTEXT=true
VITE_AGENT_CONTEXT_RETENTION_HOURS=24
VITE_AGENT_MAX_CONCURRENT_AGENTS=5

# Workflow Configurations
VITE_WORKFLOW_CODE_REVIEW_AGENTS=code-review,research
VITE_WORKFLOW_CODE_REVIEW_SEQUENCE=analyze,review,optimize
VITE_WORKFLOW_CODE_REVIEW_TIMEOUT=300

VITE_WORKFLOW_CONTENT_AGENTS=content,research,orchestrator
VITE_WORKFLOW_CONTENT_SEQUENCE=brainstorm,create,review,optimize
VITE_WORKFLOW_CONTENT_TIMEOUT=600

VITE_WORKFLOW_RESEARCH_AGENTS=research,orchestrator
VITE_WORKFLOW_RESEARCH_SEQUENCE=research,analyze,synthesize,recommend
VITE_WORKFLOW_RESEARCH_TIMEOUT=900

# Agent Monitoring & Logging
VITE_AGENT_LOG_LEVEL=info
VITE_AGENT_LOG_RETENTION_DAYS=30
VITE_AGENT_PERFORMANCE_TRACKING=true
VITE_AGENT_METRICS_ENABLED=true
VITE_AGENT_METRICS_INTERVAL=60
VITE_AGENT_ALERT_FAILURE_THRESHOLD=5

# Cost Management
VITE_AGENT_COST_TRACKING=true
VITE_AGENT_COST_ALERT_THRESHOLD=1000
VITE_AGENT_COST_MONTHLY_BUDGET=5000
VITE_AGENT_USAGE_OPTIMIZATION=true
VITE_AGENT_CACHE_ENABLED=true
VITE_AGENT_CACHE_TTL=3600

# ===== Docker Deployment Access Control Configuration =====
# The following configurations are only needed in Docker deployment, used to set web interface access control

# Access Username (optional, defaults to admin)
# ACCESS_USERNAME=admin

# Access Password (optional, no password protection if not set)
# ACCESS_PASSWORD=your_password

# ===== Development Environment Update Testing Configuration =====
# Uncomment the following configurations to enable update testing functionality in development environment

# Method 1: Use GITHUB_REPOSITORY environment variable (recommended)
# GITHUB_REPOSITORY=your-username/your-repo-name

# Method 2: Set repository owner and name separately
# DEV_REPO_OWNER=your-username
# DEV_REPO_NAME=your-repo-name

# ===== Usage Instructions =====
#
# LLM API Keys:
# 1. Use VITE_ prefix environment variables, support all modules (Web, Desktop, MCP server, etc.)
# 2. Configure corresponding API keys according to the features you use
# 3. Custom API supports local services (such as Ollama) and other OpenAI format compatible services
# 4. Multiple custom models: Use VITE_CUSTOM_API_*_<suffix> format to configure multiple custom models
#    - Support unlimited number of custom models
#    - Each model displays as a separate option in the UI
#    - Suffix names are automatically formatted into friendly display names
#
# MCP Server (only needed when using MCP functionality):
# 1. At least one API key needs to be configured to start
# 2. Execute pnpm mcp:dev in the project root directory to start the development server
# 3. If multiple API keys are configured, you can specify the preferred one through MCP_DEFAULT_MODEL_PROVIDER
# 4. MCP_DEFAULT_MODEL_PROVIDER supported values:
#    - openai: Use OpenAI GPT models
#    - gemini: Use Google Gemini models
#    - deepseek: Use DeepSeek models
#    - siliconflow: Use SiliconFlow models
#    - zhipu: Use ZhiPu AI models
#    - custom: Use custom API (such as Ollama, etc.)
#    - custom_<suffix>: Use specific multiple custom models (such as custom_qwen3)
# 5. HTTP mode default port 3000, can be modified through MCP_HTTP_PORT
# 6. Debug logging enabled by default, can be adjusted through MCP_LOG_LEVEL
#
# Google ADK (Agent Development Kit):
# 1. Requires Google Cloud Project with Vertex AI enabled
# 2. VITE_GOOGLE_ADK_PROJECT_ID and VITE_GOOGLE_ADK_LOCATION are required
# 3. Service account credentials can be provided via environment variables or Application Default Credentials
# 4. Enable/disable specific agent types via VITE_ADK_*_ENABLED flags
# 5. ADK agents support: content creation, data analysis, and code generation
# 6. Integrated with template system for enhanced AI workflows
# 7. Cost tracking and performance monitoring available
#
# Docker Deployment Access Control:
# 1. ACCESS_USERNAME and ACCESS_PASSWORD are only used in Docker deployment
# 2. No access restrictions if password is not set
# 3. Username and password required to access web interface when password is set
#
# Update Testing (only needed in development environment):
# 1. Only supports public repositories, private repositories not supported
# 2. If repository configuration is not set, will use the default public repository (linshenkx/prompt-optimizer)
# 3. Development environment now supports update testing by default, no additional configuration files needed
# 4. Update logs will be saved in the logs/auto-updater.log file in the user data directory